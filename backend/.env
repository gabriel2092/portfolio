# LLM Provider Selection
# Options: "ollama" (local, free) or "anthropic" (cloud, paid)
LLM_PROVIDER=ollama

# Ollama Configuration (for local open source models)
# Install from: https://ollama.ai
# Popular models: llama3.1:8b, mistral, qwen2.5:7b, phi3:14b
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# Anthropic API Configuration (optional, only needed if LLM_PROVIDER=anthropic)
# Get API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Application Settings
ENVIRONMENT=development
DEBUG=True
CORS_ORIGINS=["http://localhost:3000","http://localhost:5173"]

# ClinicalTrials.gov API
CLINICALTRIALS_API_URL=https://clinicaltrials.gov/api/v2

# Cache Settings
ENABLE_CACHE=True
CACHE_EXPIRY_HOURS=24
